# POC Java Spring AI

## ğŸ¤– POC â€” Spring AI com Ollama (Chat Simples)

### ğŸ“Œ 1ï¸âƒ£ Objetivo

Esta Proof of Concept (POC) demonstra a integraÃ§Ã£o entre:

- Spring AI

- Spring Boot

- Ollama

- Java 21

O objetivo da Fase 1 Ã©:

- Integrar uma LLM local

- Criar um endpoint REST

- Enviar prompts para o modelo

- Retornar resposta via API

### ğŸ—ï¸ 2ï¸âƒ£ Stack TecnolÃ³gica

### ğŸ§  3ï¸âƒ£ Arquitetura Atual (Fase 1)

Â´Â´Â´Â´
controller
 â””â”€â”€ AiController
Â´Â´Â´Â´

Fluxo:

Â´Â´Â´Â´
Client â†’ Controller â†’ ChatClient â†’ Ollama (localhost:11434) â†’ Response
Â´Â´Â´Â´
### âš™ï¸ 4ï¸âƒ£ ConfiguraÃ§Ã£o

application.yml

Â´Â´Â´Â´
spring:
  ai:
    ollama:
      base-url: http://localhost:11434
      chat:
        model: llama3
        options:
          temperature: 0.3
Â´Â´Â´Â´

### ğŸš€ 5ï¸âƒ£ ExecuÃ§Ã£o

#### 1ï¸âƒ£ Subir Ollama

Â´Â´Â´Â´
ollama run llama3
Â´Â´Â´Â´

#### 2ï¸âƒ£ Rodar aplicaÃ§Ã£o

Â´Â´Â´Â´
mvn spring-boot:run
Â´Â´Â´Â´

#### 3ï¸âƒ£ Testar endpoint

Â´Â´Â´Â´
curl "http://localhost:8080/ai/ask?question=Explique%20o%20que%20%C3%A9%20Spring%20Boot"
Â´Â´Â´Â´
